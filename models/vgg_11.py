import math

import torch.nn as nn
import torch.utils.model_zoo as model_zoo


__all__ = [
    'slimmingvgg',
]

model_urls = {
    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',
}

class VGG(nn.Module):

    def __init__(self, features, cfg, num_classes=1000, init_weights=True):
        """
        Initialize the network.

        Args:
            self: (todo): write your description
            features: (todo): write your description
            cfg: (todo): write your description
            num_classes: (int): write your description
            init_weights: (float): write your description
        """
        super(VGG, self).__init__()
        self.features = features
        self.classifier = nn.Sequential(
            nn.Linear(cfg[0] * 7 * 7, cfg[1]),
            nn.BatchNorm1d(cfg[1]),
            nn.ReLU(True),
            nn.Linear(cfg[1],cfg[2]),
            nn.BatchNorm1d(cfg[2]),
            nn.ReLU(True),
            nn.Linear(cfg[2], num_classes)
        )
        if init_weights:
            self._initialize_weights()

    def forward(self, x):
        """
        Forward computation.

        Args:
            self: (todo): write your description
            x: (todo): write your description
        """
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

    def _initialize_weights(self):
        """
        Initialize the weights.

        Args:
            self: (todo): write your description
        """
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal(m.weight, mode='fan_out')#, nonlinearity='relu')
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(0.5)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                m.weight.data.normal_(0, 0.01)
                m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm1d):
                m.weight.data.fill_(0.5)
                m.bias.data.zero_()

def make_layers(cfg, batch_norm=False):
    """
    Make layers for layers.

    Args:
        cfg: (todo): write your description
        batch_norm: (todo): write your description
    """
    layers = []
    in_channels = 3
    for v in cfg:
        if v == 'M':
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
        else:
            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
            if batch_norm:
                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
            else:
                layers += [conv2d, nn.ReLU(inplace=True)]
            in_channels = v
    return nn.Sequential(*layers)

cfg = {
    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M', 4096, 4096]
}

def slimmingvgg(pretrained=False, depth=None, dataset=None, config=None, **kwargs):
    """VGG 11-layer model (configuration "A") with batch normalization

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    if pretrained:
        kwargs['init_weights'] = False
    if config == None:
        config = cfg['A']
    config2 = [config[-4],config[-2],config[-1]]
    model = VGG(make_layers(config[:-2], batch_norm=True), config2, **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))
    return model